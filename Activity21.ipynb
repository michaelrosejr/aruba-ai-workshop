{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32436950-5716-4e1a-aacd-e87bc25d63b0",
   "metadata": {},
   "source": [
    "# Image Classification\n",
    "## Switch vs. Access Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d4712f-9015-4b26-bf4a-8259c426ccbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display as print\n",
    "from IPython.display import Image, display, Markdown\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "\n",
    "### Uncomment the following if running your own server that has a GPU.\n",
    "### The following will prevent tensorflow use ALL of your GPU\n",
    "### or you'll get out of memory errors with other applications\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for gpu in gpus:\n",
    "#     tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "data = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=\"../data\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd921d5-f09c-48c5-8649-6a7bb1d89167",
   "metadata": {},
   "source": [
    "### The following will generate an error. The error can be ignored.\n",
    "\n",
    "The following will load the dataset into numpy and cycle through the shapes using the Python generator, next().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0b092c-fe7f-46f4-bb85-a9476118ecf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_iterator = data.as_numpy_iterator()  # type: ignore\n",
    "batch = data_iterator.next()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19e26ce-46e7-42da-ad63-bb6f2765ca42",
   "metadata": {},
   "source": [
    "### Print the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8c2082-c18b-479c-bb7e-4bbc58400bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the batch \n",
    "# 0 is access points\n",
    "# 1 is switches\n",
    "\n",
    "print(batch[0].shape)\n",
    "print(batch[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9487756f-b606-4677-93f7-93915350b0d4",
   "metadata": {},
   "source": [
    "## Show images from batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6a56d2-c14f-4f77-8a2d-1c8624f3b724",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20, 20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img.astype(np.uint8))\n",
    "    ax[idx].title.set_text(batch[1][idx])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881e7638-1cc6-429d-ae80-4d9f48177217",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SCALE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce170724-3adc-49fc-b000-e75aa0fa3665",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data = data.map(lambda x, y: (x/255, y))  # type: ignore\n",
    "scaled_iterator = data.as_numpy_iterator()\n",
    "batch = scaled_iterator.next()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff998d4-376f-49dd-97a7-1590cd96e2f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Display Scaled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd639b44-ef59-47d7-95bd-044e3b1dd5a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20, 20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img)\n",
    "    ax[idx].title.set_text(batch[1][idx])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b0d925-cb96-40ca-b39e-c4a9dbddab32",
   "metadata": {},
   "source": [
    "## SPLIT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6713914d-e884-4d91-97c1-8df63b22030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(data))\n",
    "train_size = int(len(data)*.7)\n",
    "val_size = int(len(data)*.2)+1\n",
    "test_size = int(len(data)*.1)+1\n",
    "\n",
    "# print(train_size+val_size+test_size)\n",
    "\n",
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size+val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df255509-3f44-4f2d-89ce-ff9c3cdc35bb",
   "metadata": {},
   "source": [
    "## Build Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc443bc-310d-4cea-87eb-dadbd507600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import (Conv2D, Dense, Flatten, MaxPooling2D)\n",
    "from tensorflow.keras.models import Sequential  # type: ignore\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), 1, activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(32, (3, 3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(16, (3, 3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057fe8a7-fcbc-4afd-bfd5-4cf62068ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21822c38-99b3-4114-8b4c-ac132af5599a",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "The training process can take a significant amount of time. On my personal machine, this took roughly 5 seconds. \n",
    "On shared hosting and training environments, this can take 2 or more minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036ae085-5f5c-49f6-b3e1-1ac9c9f70a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logdir = 'logs'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "hist = model.fit(train, epochs=20, validation_data=val, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bba9f2-472f-4b5c-baae-660ba7dfbde7",
   "metadata": {},
   "source": [
    "## Plot Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceca386f-32d9-4962-a0b2-86734dcfdc46",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954ca972-3c70-4000-8d5e-cd21f2aeb1e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "##\n",
    "# Loss\n",
    "#\n",
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7950ed9-b9af-4dc3-9478-f2e08a255250",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbdb2d0-7f20-42b5-85a1-0137556cac41",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Accuracy\n",
    "#\n",
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd3b4ef-908f-4d37-8621-413950c1630a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa59390a-00b0-43e8-abb7-8746c0e4b52a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "####\n",
    "# Evaluate Model\n",
    "#\n",
    "# from tensorflow.keras.metrics import BinaryAccuracy  # type: ignore\n",
    "# from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "# pre = Precision()\n",
    "# re = Recall()\n",
    "# acc = BinaryAccuracy()\n",
    "\n",
    "# for batch in test.as_numpy_iterator():\n",
    "#     X, y = batch\n",
    "#     yhat = model.predict(X)\n",
    "#     pre.update_state(y, yhat)\n",
    "#     re.update_state(y, yhat)\n",
    "#     acc.update_state(y, yhat)\n",
    "\n",
    "# print(pre.result(), re.result(), acc.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49020d4d-e61f-4282-b55e-137637011a51",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36c0ecc-aee2-4396-9cc2-4dd632f5ad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Test Model\n",
    "#\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('test_images/test_switch-1.png')\n",
    "resize = tf.image.resize(img, (256, 256))\n",
    "plt.imshow(resize.numpy().astype(int))  # type: ignore\n",
    "plt.show()\n",
    "\n",
    "yhat = model.predict(np.expand_dims(resize/255, 0))  # type: ignore\n",
    "\n",
    "if yhat > 0.5:\n",
    "    print('Predicted class of image is a Switch')\n",
    "else:\n",
    "    print('Predicted class of image is an Access Point')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d034dc-07c8-48a3-bc8c-b681e2951e93",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740624fd-1af9-4a81-9aa0-cbd2412f6cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Save Model\n",
    "#\n",
    "import os\n",
    "model.save(os.path.join('models', 'imageclassifier.h5'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aruba-ai-workshop-tf",
   "language": "python",
   "name": "aruba-ai-workshop-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
