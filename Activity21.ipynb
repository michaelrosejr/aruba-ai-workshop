{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32436950-5716-4e1a-aacd-e87bc25d63b0",
   "metadata": {},
   "source": [
    "# <span style='color:#DB822E'>Activity 21: Switch vs. Access Point</span>\n",
    "\n",
    "In this activity we'll build our own custom deep learning image classifier to compare images of Aruba devices and determine if the picture is an AP or switch. We'll use a collection of Aruba images from the web. We'll then load those images into a pipeline and use it to classify images as a zero or one binary classification type problem. \n",
    "\n",
    "We'll be using [Tensorflow](https://www.tensorflow.org/), specifically the [Keras API](https://www.tensorflow.org/guide/keras) within [Tensorflow](https://www.tensorflow.org/) to build this deep learning classifier.\n",
    "\n",
    ">TensorFlow is an end-to-end open source platform for machine learning. TensorFlow is a rich system for managing all aspects of a machine learning system; however, this class focuses on using a particular TensorFlow API to develop and train machine learning models.\n",
    "\n",
    ">Keras is the high-level API (developed by Google) of the TensorFlow platform. It provides an approachable, highly-productive interface for solving machine learning (ML) problems, with a focus on modern deep learning. Keras covers every step of the machine learning workflow, from data processing to hyperparameter tuning to deployment.\n",
    "\n",
    "\n",
    "## STEP 1 - First we'll load all the necessary Python modules for this activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d4712f-9015-4b26-bf4a-8259c426ccbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from IPython.display import Image, display, Markdown\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "\n",
    "\n",
    "display(Markdown('<span style=\"color: #14B326\">Done!</span>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a90eb48-c9ac-4f38-9ee9-357a9836a2b0",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## STEP 2\n",
    "\n",
    "\n",
    "Next we'll be using Tensorflow's Keras sequential api utility to load the images from our data direcotry. This will make it easier to build our custom deep learning module over Tensorflows dataset utility. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b91a25-b5e1-4b1c-9b32-b92dff786d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uncomment the following if running your own server that has a GPU.\n",
    "### The following will prevent tensorflow use ALL of your GPU\n",
    "### or you'll get out of memory errors with other applications\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for gpu in gpus:\n",
    "#     tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "data = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=\"data\"\n",
    "    )\n",
    "\n",
    "display(Markdown('<span style=\"color: #14B326\">Done!</span>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd921d5-f09c-48c5-8649-6a7bb1d89167",
   "metadata": {},
   "source": [
    "<span style='color:red'>The following may generate an error. The error can be ignored.</span>\n",
    "\n",
    "***\n",
    "## STEP 3\n",
    "\n",
    "The following will load the dataset into numpy and cycle through the shapes using the Python generator, next().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0b092c-fe7f-46f4-bb85-a9476118ecf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_iterator = data.as_numpy_iterator()  # type: ignore\n",
    "batch = data_iterator.next()\n",
    "\n",
    "display(Markdown('<span style=\"color: #14B326\">Done!</span>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19e26ce-46e7-42da-ad63-bb6f2765ca42",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "\n",
    "\n",
    "## STEP 4 -  Print the batch\n",
    "\n",
    "index 0 or shape, is the image data\n",
    "index 1 is the label\n",
    "\n",
    "32 is the batch (default)\n",
    "256, 256 is auto resizing it to 256x256 px\n",
    "3 is RGB (red green blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8c2082-c18b-479c-bb7e-4bbc58400bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the batch \n",
    "# 0 is access points\n",
    "# 1 is switches\n",
    "\n",
    "display(batch[0].shape)\n",
    "display(batch[1])\n",
    "\n",
    "display(Markdown('<span style=\"color: #14B326\">Done!</span>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9487756f-b606-4677-93f7-93915350b0d4",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## STEP 5 - Show images from batch\n",
    "\n",
    "Here we'll display some of the data so we can see if it looks correct.\n",
    "ncols is the number of columns\n",
    "figsize is the figure size, so 20x20 to fit on our screen\n",
    ":4 says to show 4 images.\n",
    "imshow is the image\n",
    "title is the title of the image, which is 0 or 1\n",
    "\n",
    "Why is AP 0 and Switch 1?\n",
    "\n",
    "This is due to how the directories or were imported. APs were first, then switches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6a56d2-c14f-4f77-8a2d-1c8624f3b724",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20, 20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img.astype(np.uint8))\n",
    "    ax[idx].title.set_text(batch[1][idx])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "display(Markdown('<span style=\"color: #14B326\">Done!</span>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881e7638-1cc6-429d-ae80-4d9f48177217",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "\n",
    "## STEP 6 - Preprocessing our data/Scale the Data\n",
    "We then need to scale the data to 255 colors. Each channel (R,G,B) have 256 colors, but we start at 0, which is why we're at 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce170724-3adc-49fc-b000-e75aa0fa3665",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data = data.map(lambda x, y: (x/255, y))  # type: ignore\n",
    "scaled_iterator = data.as_numpy_iterator()\n",
    "batch = scaled_iterator.next()\n",
    "\n",
    "display(Markdown('<span style=\"color: #14B326\">Done!</span>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff998d4-376f-49dd-97a7-1590cd96e2f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "\n",
    "## STEP 7 - Display Scaled Data\n",
    "\n",
    "Again, we display the data now that we've scaled the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd639b44-ef59-47d7-95bd-044e3b1dd5a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20, 20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img)\n",
    "    ax[idx].title.set_text(batch[1][idx])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "display(Markdown('<span style=\"color: #14B326\">Done!</span>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b0d925-cb96-40ca-b39e-c4a9dbddab32",
   "metadata": {},
   "source": [
    "## STEP 8 - SPLIT DATA\n",
    "\n",
    "In this section, we'll be split the data just as we did in our previous activities.\n",
    "We'll do 70% of the images for training\n",
    "then, 20% for validating the images\n",
    "finally, 10% to test that data. The testing will be done at the end of the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6713914d-e884-4d91-97c1-8df63b22030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(data))\n",
    "train_size = int(len(data)*.7)\n",
    "val_size = int(len(data)*.2)+1\n",
    "test_size = int(len(data)*.1)+1\n",
    "\n",
    "# print(train_size+val_size+test_size)\n",
    "\n",
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size+val_size).take(test_size)\n",
    "\n",
    "display(Markdown('<span style=\"color: #14B326\">Done!</span>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df255509-3f44-4f2d-89ce-ff9c3cdc35bb",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "\n",
    "## STEP 9 - Build Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc443bc-310d-4cea-87eb-dadbd507600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import (Conv2D, Dense, Flatten, MaxPooling2D)\n",
    "from tensorflow.keras.models import Sequential  # type: ignore\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), 1, activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(32, (3, 3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(16, (3, 3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "display(Markdown('<span style=\"color: #14B326\">Done!</span>'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057fe8a7-fcbc-4afd-bfd5-4cf62068ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the model\n",
    "print(model.summary())\n",
    "\n",
    "display(Markdown('<span style=\"color: #14B326\">Done!</span>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21822c38-99b3-4114-8b4c-ac132af5599a",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## STEP 10 Train Model\n",
    "\n",
    "The training process can take a significant amount of time. On my personal machine, this took roughly 5 seconds. \n",
    "On shared hosting and training environments, <span style=\"color: #ff0000\">this can take 2 or more minutes!</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036ae085-5f5c-49f6-b3e1-1ac9c9f70a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logdir = 'logs'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "hist = model.fit(train, epochs=20, validation_data=val, callbacks=[tensorboard_callback])\n",
    "\n",
    "display(Markdown('<span style=\"color: #14B326\">Done!</span>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bba9f2-472f-4b5c-baae-660ba7dfbde7",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## STEP 11 - Plot Performance\n",
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954ca972-3c70-4000-8d5e-cd21f2aeb1e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "##\n",
    "# Loss\n",
    "#\n",
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "display(Markdown('<span style=\"color: #14B326\">Done!</span>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7950ed9-b9af-4dc3-9478-f2e08a255250",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbdb2d0-7f20-42b5-85a1-0137556cac41",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Accuracy\n",
    "#\n",
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "display(Markdown('<span style=\"color: #14B326\">Done!</span>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd3b4ef-908f-4d37-8621-413950c1630a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa59390a-00b0-43e8-abb7-8746c0e4b52a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####\n",
    "# Evaluate Model\n",
    "#\n",
    "# from tensorflow.keras.metrics import BinaryAccuracy  # type: ignore\n",
    "# from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "# pre = Precision()\n",
    "# re = Recall()\n",
    "# acc = BinaryAccuracy()\n",
    "\n",
    "# for batch in test.as_numpy_iterator():\n",
    "#     X, y = batch\n",
    "#     yhat = model.predict(X)\n",
    "#     pre.update_state(y, yhat)\n",
    "#     re.update_state(y, yhat)\n",
    "#     acc.update_state(y, yhat)\n",
    "\n",
    "# print(pre.result(), re.result(), acc.result())\n",
    "\n",
    "display(Markdown('<span style=\"color: #14B326\">Done!</span>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49020d4d-e61f-4282-b55e-137637011a51",
   "metadata": {},
   "source": [
    "## STEP 12 - Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36c0ecc-aee2-4396-9cc2-4dd632f5ad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Test Model\n",
    "#\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('test_images/test_switch-1.png')\n",
    "resize = tf.image.resize(img, (256, 256))\n",
    "plt.imshow(resize.numpy().astype(int))  # type: ignore\n",
    "plt.show()\n",
    "\n",
    "yhat = model.predict(np.expand_dims(resize/255, 0))  # type: ignore\n",
    "\n",
    "if yhat > 0.5:\n",
    "    display('Predicted class of image is a Switch')\n",
    "else:\n",
    "    display('Predicted class of image is an Access Point')\n",
    "    \n",
    "display(Markdown('<span style=\"color: #14B326\">Done!</span>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d034dc-07c8-48a3-bc8c-b681e2951e93",
   "metadata": {},
   "source": [
    "## Step 13 - Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740624fd-1af9-4a81-9aa0-cbd2412f6cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####\n",
    "# Save Model\n",
    "#\n",
    "import os\n",
    "model.save(os.path.join('models', 'imageclassifier.keras'))\n",
    "\n",
    "display(Markdown('<span style=\"color: #14B326\">Done!</span>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8aa14e-db4a-43f1-8882-e334668aef2e",
   "metadata": {},
   "source": [
    "## You have completed Activity 21.\n",
    "\n",
    "[Start Activity 22](Activity22.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
