{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32436950-5716-4e1a-aacd-e87bc25d63b0",
   "metadata": {},
   "source": [
    "# <span style='color:#DB822E'>Activity 21: Image Recognition Using Deep Learning</span>\n",
    "## Access Point or Switch?\n",
    "\n",
    "In this activity we'll build our own custom deep learning image classifier to compare images of Aruba devices and determine if the picture is an AP or switch. We'll use a collection of Aruba images from the web. We'll then load those images into a pipeline and use it to classify images as a zero or one binary classification type problem. \n",
    "\n",
    "We'll be using [Tensorflow](https://www.tensorflow.org/), specifically the [Keras API](https://www.tensorflow.org/guide/keras) within Tensorflow to build this deep learning classifier.\n",
    "\n",
    "- `TensorFlow` is an end-to-end open-source platform for machine learning. TensorFlow is a rich system for managing all aspects of a machine learning system; however, this class focuses on using a particular TensorFlow API to develop and train machine learning models.\n",
    "\n",
    "- `Keras` (developed by Google)is the high-level API of the TensorFlow platform. It provides an approachable, highly productive interface for solving machine learning (ML) problems, with a focus on modern deep learning. Keras covers every step of the machine learning workflow, from data processing to hyperparameter tuning to deployment.\n",
    "\n",
    "\n",
    "## Step 1 - Establish the Environment\n",
    "Once again, we will setup the lab environment by importing and loading some the libraries required for running the models in this lab.\n",
    "\n",
    "- `matplotlib` - Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python.\n",
    "\n",
    "Let's get started.  Run the code block. üëáüèΩ\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d4712f-9015-4b26-bf4a-8259c426ccbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from IPython.display import Image, display, Markdown\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "\n",
    "\n",
    "display(Markdown('<span style=\"color: #14B326\">Done!</span>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a90eb48-c9ac-4f38-9ee9-357a9836a2b0",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Step 2 - Load the Dataset with Keras API\n",
    "\n",
    "\n",
    "The Keras sequential API utility to load the images from our data directory. This will make it easier to build our custom deep learning module over Tensorflows dataset utility. \n",
    "\n",
    "The interesting thing about this step is that the concept of GPU comes into playnand we did not talk about this much in the workshop.\n",
    " - **G**raphics **P**rocessing **U**nit (GPU) is a specialized electronic circuit designed to rapidly manipulate and display images. GPUs are used in a wide range of applications, including video games, video editing, scientific computing and AI.  GPUs are well-suited for deep learning because they have many cores that can be used to perform parallel computations. This means that GPUs can process multiple pieces of data at the same time, which can significantly speed up the training process.\n",
    "\n",
    "Deep Learning models are much more of a resource drain than machine learning.  In this code, you are  initializing a MirroredStrategy and loading a dataset of images from the data directory.\n",
    "\n",
    "`tf.distribute.MirroredStrategy()` creates a strategy that replicates the model and data across all available GPUs. This allows you to train your model on multiple GPUs in parallel, which can significantly speed up training.  In short, in the world of AI, GPU's and things like mirrored strategies are critical to ensure performance.\n",
    "\n",
    "Let's Run it! üëáüèΩ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b91a25-b5e1-4b1c-9b32-b92dff786d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uncomment the following if running your own server that has a GPU.\n",
    "### The following will prevent tensorflow use ALL of your GPU\n",
    "### or you'll get out of memory errors with other applications\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for gpu in gpus:\n",
    "#     tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "\n",
    "data = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=\"data\"\n",
    "    )\n",
    "\n",
    "display(Markdown('<span style=\"color: #14B326\">Done!</span>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd921d5-f09c-48c5-8649-6a7bb1d89167",
   "metadata": {},
   "source": [
    "\n",
    "## Step 3 - Data Iterator\n",
    "A NumPy data iterator is an object that provides a way to iterate over the elements of a NumPy array in a systematic way. Iterators are useful for performing a variety of operations on NumPy arrays, such as:\n",
    "\n",
    "- Applying a function to each element of an array\n",
    "- Performing element-wise arithmetic on two arrays\n",
    "- Finding the minimum and maximum values in an array\n",
    "- Sorting an array\n",
    "- Creating a new array from a subset of the elements of an existing array\n",
    "\n",
    "\n",
    "This code provides a simple but efficient way to load batches of data for machine learning applications for training a neural network. The following will load the dataset into numpy and cycle through the shapes using the Python generator, next().\n",
    "\n",
    "**üîªüîª <span style='color:red'>WARNING!! The following üëá may generate an error. The error can be ignored.</span> üîªüîª**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0b092c-fe7f-46f4-bb85-a9476118ecf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_iterator = data.as_numpy_iterator()  # type: ignore\n",
    "batch = data_iterator.next()\n",
    "\n",
    "display(Markdown('<span style=\"color: #14B326\">Done!</span>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19e26ce-46e7-42da-ad63-bb6f2765ca42",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "\n",
    "\n",
    "## Step 4 -  Print the Batch\n",
    "\n",
    "Prints the shape and values of the first batch of data, which contains access points and switches.\n",
    "\n",
    "Index 0 or shape, is the image data\n",
    "Index 1 is the label\n",
    "\n",
    "32 is the batch (default)\n",
    "256, 256 is auto resizing it to 256x256 px\n",
    "3 is RGB (red green blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8c2082-c18b-479c-bb7e-4bbc58400bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the batch \n",
    "# 0 is access points\n",
    "# 1 is switches\n",
    "\n",
    "display(batch[0].shape)\n",
    "display(batch[1])\n",
    "\n",
    "display(Markdown('<span style=\"color: #14B326\">Done!</span>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9487756f-b606-4677-93f7-93915350b0d4",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Step 5 - Visualize the Data\n",
    "\n",
    "This code is a useful way to visualize the batches of access points and switches in the dataset. This can be helpful for debugging purposes or for understanding the data that is being processed. Here we'll display some of the data so we can see if it looks correct.\n",
    "\n",
    "`fig, ax = plt.subplots(ncols=4, figsize=(20, 20))`\n",
    "- `ncols` is the number of columns\n",
    "- `figsize` is the figure size, so 20x20 to fit on our screen\n",
    "\n",
    "```\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img.astype(np.uint8))\n",
    "    ax[idx].title.set_text(batch[1][idx])\n",
    "```\n",
    "\n",
    "- `:4` says to show 4 images.\n",
    "- `imshow` is the image\n",
    "- `title` is the title of the image, which is 0 or 1\n",
    "\n",
    "AP is equal to 0 and switch is equalt to 1 because of how the directories or were imported. APs were first, then switches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6a56d2-c14f-4f77-8a2d-1c8624f3b724",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20, 20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img.astype(np.uint8))\n",
    "    ax[idx].title.set_text(batch[1][idx])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "display(Markdown('<span style=\"color: #14B326\">Done!  Onward.  Step 6  next.</span>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881e7638-1cc6-429d-ae80-4d9f48177217",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "\n",
    "## Step 6 - Scale the Data to Improve Performance\n",
    "We then need to scale the data to 255 colors. Each channel (R,G,B) have 256 colors, but we start at 0, which is why we're at 255.\n",
    "\n",
    "This code scales the data NumPy array by dividing each value by 255. This is a common data preprocessing technique for machine learning applications, as it helps to normalize the data and improve the performance of the model.  Let's givie it a try üëáüèø"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce170724-3adc-49fc-b000-e75aa0fa3665",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data = data.map(lambda x, y: (x/255, y))  # type: ignore\n",
    "scaled_iterator = data.as_numpy_iterator()\n",
    "batch = scaled_iterator.next()\n",
    "\n",
    "display(Markdown('<span style=\"color: #14B326\">Done! Step 7 next.</span>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff998d4-376f-49dd-97a7-1590cd96e2f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "\n",
    "## Step 7 - Display Scaled Data\n",
    "\n",
    "Just as in Step 5, will display some of our data.  Visualizing data is helpful for debugging purposes or for understanding the data that is being processed. Let's run the code and take a look. üëáüèø"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd639b44-ef59-47d7-95bd-044e3b1dd5a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20, 20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img)\n",
    "    ax[idx].title.set_text(batch[1][idx])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "display(Markdown('<span style=\"color: #14B326\">Done! Step 8 next.</span>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed531e5-64b9-4da0-8410-b4ac12a86121",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Step 8 - Split Dataset 3 Ways (Training, Validation & Test Data)\n",
    "\n",
    "As in previous activities this step will split the data. The dataset is split into three subsets: train, validation, and test. The train subset is used to train the model, the validation subset is used to evaluate the model during training, and the test subset is used to evaluate the model after training is complete.\n",
    "\n",
    "The code first calculates the size of each subset by multiplying the total size of the dataset by the desired percentage. The train subset is then created by taking the first train_size elements of the dataset. The validation subset is created by skipping the first train_size elements of the dataset and then taking the next val_size elements. The test subset is created by skipping the first train_size and val_size elements of the dataset and then taking the next test_size elements.\n",
    "\n",
    "Let's run the code üëá."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6713914d-e884-4d91-97c1-8df63b22030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(data))\n",
    "train_size = int(len(data)*.7)\n",
    "val_size = int(len(data)*.2)+1\n",
    "test_size = int(len(data)*.1)+1\n",
    "\n",
    "# print(train_size+val_size+test_size)\n",
    "\n",
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size+val_size).take(test_size)\n",
    "\n",
    "display(Markdown('<span style=\"color: #14B326\">Done! On to step 9.</span>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df255509-3f44-4f2d-89ce-ff9c3cdc35bb",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "\n",
    "## Step 9 - Building Deep Learning Model\n",
    "\n",
    "This code creates a simple convolutional neural network (CNN) model for image classification.  Once the model is trained, you can use it to predict the class of new images.\n",
    "\n",
    "CNNs are a powerful tool for image classification, and they have been shown to achieve state-of-the-art results on many benchmark datasets. This is a simple example of a CNN model, and it can be used as a starting point for building more complex models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc443bc-310d-4cea-87eb-dadbd507600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import (Conv2D, Dense, Flatten, MaxPooling2D)\n",
    "from tensorflow.keras.models import Sequential  # type: ignore\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), 1, activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(32, (3, 3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(16, (3, 3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "display(Markdown('<span style=\"color: #14B326\">Done! Onward! Step 10 next</span>'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057fe8a7-fcbc-4afd-bfd5-4cf62068ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the model\n",
    "print(model.summary())\n",
    "\n",
    "display(Markdown('<span style=\"color: #14B326\">Done!</span>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21822c38-99b3-4114-8b4c-ac132af5599a",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Step 10 Training the Model\n",
    "\n",
    "This code does the following:\n",
    "\n",
    "1. Defines a log directory called logs where TensorBoard will save its logs.\n",
    "2. Creates a TensorBoard callback that will log the model's performance to the logs directory.\n",
    "3. Sets the device to the first GPU.\n",
    "4. Trains the model on the train dataset for 20 epochs, with the val dataset used for validation.\n",
    "5. Uses the TensorBoard callback to log the model's performance during training.\n",
    "\n",
    "The `with tf.device(f'/GPU:0'):` block ensures that the model is trained on the first GPU. This can improve the training speed significantly, especially for large and complex models.\n",
    "\n",
    "The TensorBoard callback is a powerful tool for visualizing the model's performance during training. It allows you to track the model's loss and accuracy on the training and validation datasets, as well as other metrics such as the training time and the weights of the model's layers.\n",
    "\n",
    "**üîªüîª <span style='color:red'>WARNING!! This step can take 3 minutes or more.</span> üîªüîª**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036ae085-5f5c-49f6-b3e1-1ac9c9f70a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logdir = 'logs'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "display(Markdown('<span style=\"color: red\">This will run 20 steps, with the first one taking a few minutes. Please be patient, it will go quickly after the first step.</span>'))\n",
    "\n",
    "with tf.device(f'/GPU:0'):\n",
    "    hist = model.fit(train, epochs=20, validation_data=val, callbacks=[tensorboard_callback])\n",
    "\n",
    "display(Markdown('<span style=\"color: #14B326\">Done! Step 11 is next.</span>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bba9f2-472f-4b5c-baae-660ba7dfbde7",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Step 11 - Plotting the Performance\n",
    "The goal of this step is to gain valuable insights into the performance of the model and make informed decisions about how to train and evaluate the model.\n",
    "\n",
    "Let's introduce some new terminology not covered during the workshop.\n",
    "\n",
    "- **`overfitting`** is a phenomenon that occurs when a machine learning model learns the training data too well and is unable to generalize to new data. This can happen when the model is too complex or when the training data is too small.\n",
    "  \n",
    "- **`underfitting`** is a phenomenon that occurs when a machine learning model is not complex enough to learn the underlying patterns in the training data. This can happen when the model is too simple or when the training data is too complex.\n",
    "\n",
    "### 11a. Loss\n",
    "The loss curves can be used to diagnose problems with the model and to determine when to stop training the model. For example, if the training loss curve decreases over time but the validation loss curve does not, this may indicate that the model is overfitting to the training data.\n",
    "\n",
    "Let's try step 11a. üëáüèø"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954ca972-3c70-4000-8d5e-cd21f2aeb1e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "##\n",
    "# Loss\n",
    "#\n",
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "display(Markdown('<span style=\"color: #14B326\">WellDone!  Notice the loss curves flattening out!</span>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7950ed9-b9af-4dc3-9478-f2e08a255250",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "\n",
    "### 11b. Accuracy\n",
    "\n",
    "This code plots the training and validation accuracy curves for the model. The training accuracy curve shows how the accuracy on the training data increases over time as the model is trained. The validation accuracy curve shows how the accuracy on the validation data changes over time.  You can use the training and validation accuracy curves to determine when to stop training the model. A common rule of thumb is to stop training the model when the validation accuracy curve starts to plateau. This means that the validation accuracy is no longer improving, even though you are continuing to train the model.\n",
    "\n",
    "**By monitoring the training and validation accuracy curves, you can train a model that is able to generalize well to new data.**\n",
    "\n",
    "Try it now üëáüèø"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbdb2d0-7f20-42b5-85a1-0137556cac41",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Accuracy\n",
    "#\n",
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "display(Markdown('<span style=\"color: #14B326\">Done! Notice the accuracy curves plateauing in the upper right?.</span>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd3b4ef-908f-4d37-8621-413950c1630a",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "\n",
    "### 11c. Evaluate Model\n",
    "\n",
    "Evaluates the performance of the model on the test dataset.  By evaluating the performance of the model on the test dataset, you can get a sense of how well the model is likely to perform on new data.\n",
    "\n",
    "This code has been commented out as it's a bit difficult to explaind and outside the scope of this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa59390a-00b0-43e8-abb7-8746c0e4b52a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####\n",
    "# Evaluate Model\n",
    "#\n",
    "# from tensorflow.keras.metrics import BinaryAccuracy  # type: ignore\n",
    "# from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "# pre = Precision()\n",
    "# re = Recall()\n",
    "# acc = BinaryAccuracy()\n",
    "\n",
    "# for batch in test.as_numpy_iterator():\n",
    "#     X, y = batch\n",
    "#     yhat = model.predict(X)\n",
    "#     pre.update_state(y, yhat)\n",
    "#     re.update_state(y, yhat)\n",
    "#     acc.update_state(y, yhat)\n",
    "\n",
    "# print(pre.result(), re.result(), acc.result())\n",
    "\n",
    "display(Markdown('<span style=\"color: #14B326\">Done! Keep moving almost there.</span>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49020d4d-e61f-4282-b55e-137637011a51",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Step 12 - Testing the Model\n",
    "\n",
    "This code will test the model on any test image. This can help you to assess the performance of the model on real-world data.\n",
    "\n",
    "1. The code first reads the test image using the `cv2.imread()` function.\n",
    "2. The code then resizes the image to 256x256 using the `tf.image.resize()` function.\n",
    "3. The code then displays the resized image using the `plt.imshow()` function.\n",
    "4. The code then predicts the class of the image using the `model.predict()` function.\n",
    "5. The `np.expand_dims()` function is used to add an extra dimension to the image, so that it can be passed to the `model.predict()` function.\n",
    "6. The `model.predict()` function returns a probability that the image belongs to the positive class.\n",
    "7. The code then checks if the probability is greater than 0.5.\n",
    "9. If it is, then the code displays a message that the predicted class of the image is a switch. Otherwise, the code displays a message that the predicted class of the image is an access point.\n",
    "\n",
    "Go for it üëá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36c0ecc-aee2-4396-9cc2-4dd632f5ad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Test Model\n",
    "#\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('test_images/test_switch-1.png')\n",
    "resize = tf.image.resize(img, (256, 256))\n",
    "plt.imshow(resize.numpy().astype(int))  # type: ignore\n",
    "plt.show()\n",
    "\n",
    "yhat = model.predict(np.expand_dims(resize/255, 0))  # type: ignore\n",
    "\n",
    "if yhat > 0.5:\n",
    "    display('Predicted class of image is a Switch')\n",
    "else:\n",
    "    display('Predicted class of image is an Access Point')\n",
    "    \n",
    "display(Markdown('<span style=\"color: #14B326\">Done! Woohooo!</span>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d034dc-07c8-48a3-bc8c-b681e2951e93",
   "metadata": {},
   "source": [
    "## Step 13 - Save the Model\n",
    "\n",
    "Saves the model to a file called imageclassifier.keras in the models directory.  Saving the model is a good practice, as it allows you to reload the model at a later time or share it with others. Do itüëá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740624fd-1af9-4a81-9aa0-cbd2412f6cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####\n",
    "# Save Model\n",
    "#\n",
    "import os\n",
    "model.save(os.path.join('models', 'imageclassifier.keras'))\n",
    "\n",
    "display(Markdown('<span style=\"color: #14B326\">Done! YESSSSS üí™üèΩüí™üèΩüí™üèΩüí™üèΩ Activity 21 is done!!!</span>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8aa14e-db4a-43f1-8882-e334668aef2e",
   "metadata": {},
   "source": [
    "## You have completed Activity 21.\n",
    "\n",
    "[Start Activity 22](Activity22.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
